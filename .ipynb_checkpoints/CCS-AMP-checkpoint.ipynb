{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCS-AMP for unsourced multiple access\n",
    "\n",
    "This notebook contains CCS-AMP encoder/decoder for unsourced multiple access using Hadamard design matrices.\n",
    "\n",
    "The proposed algorithm goes back and forth between inner AMP and outer tree decoding components.\n",
    "\n",
    "The code is based on the following articles:\n",
    "\n",
    "A coded compressed sensing scheme for uncoordinated multiple access, available @ https://arxiv.org/pdf/1809.04745.pdf\n",
    "\n",
    "SPARCs for Unsourced Random Access, available @ https://arxiv.org/abs/1901.06234\n",
    "\n",
    "On Approximate Message Passing for Unsourced Access with Coded Compressed Sensing, available @ https://arxiv.org/pdf/2001.03705.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipdb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fht(u):\n",
    "    \"\"\"\n",
    "    Perform fast Hadamard transform of u, in-place.\n",
    "    Note len(u) must be a power of two.\n",
    "    \"\"\"\n",
    "    N = len(u)\n",
    "    i = N>>1\n",
    "    while i:\n",
    "        for j in range(N):\n",
    "            if (i&j) == 0:\n",
    "                temp = u[j]\n",
    "                u[j] += u[i|j]\n",
    "                u[i|j] = temp - u[i|j]\n",
    "        i>>= 1\n",
    "\n",
    "def sub_fht(n, m, seed=0, ordering=None, new_embedding=False):\n",
    "    \"\"\"\n",
    "    Returns functions to compute the sub-sampled Walsh-Hadamard transform,\n",
    "    i.e., operating with a wide rectangular matrix of random +/-1 entries.\n",
    "\n",
    "    n: number of rows\n",
    "    m: number of columns\n",
    "\n",
    "    It is most efficient (but not required) for max(m,n+1) to be a power of 2.\n",
    "\n",
    "    seed: determines choice of random matrix\n",
    "    ordering: optional n-long array of row indices in [1, max(m,n)] to\n",
    "              implement subsampling; generated by seed if not specified,\n",
    "              but may be given to speed up subsequent runs on the same matrix.\n",
    "\n",
    "    Returns (Ax, Ay, ordering):\n",
    "        Ax(x): computes A.x (of length n), with x having length m\n",
    "        Ay(y): computes A'.y (of length m), with y having length n\n",
    "        ordering: the ordering in use, which may have been generated from seed\n",
    "    \"\"\"\n",
    "    assert n > 0, \"n must be positive\"\n",
    "    assert m > 0, \"m must be positive\"\n",
    "    if new_embedding:\n",
    "        w = 2**int(np.ceil(np.log2(max(m+1, n+1))))\n",
    "    else:\n",
    "        w = 2**int(np.ceil(np.log2(max(m, n+1))))\n",
    "\n",
    "    if ordering is not None:\n",
    "        assert ordering.shape == (n,)\n",
    "    else:\n",
    "        rng = np.random.RandomState(seed)\n",
    "        idxs = np.arange(1, w, dtype=np.uint32)\n",
    "        rng.shuffle(idxs)\n",
    "        ordering = idxs[:n]\n",
    "\n",
    "    def Ax(x):\n",
    "        assert x.size == m, \"x must be m long\"\n",
    "        y = np.zeros(w)\n",
    "        if new_embedding:\n",
    "            y[w-m:] = x.reshape(m)\n",
    "        else:\n",
    "            y[:m] = x.reshape(m)\n",
    "        fht(y)\n",
    "        return y[ordering]\n",
    "\n",
    "    def Ay(y):\n",
    "        assert y.size == n, \"input must be n long\"\n",
    "        x = np.zeros(w)\n",
    "        x[ordering] = y.reshape(n)\n",
    "        fht(x)\n",
    "        if new_embedding:\n",
    "            return x[w-m:]\n",
    "        else:\n",
    "            return x[:m]\n",
    "\n",
    "    return Ax, Ay, ordering\n",
    "\n",
    "def block_sub_fht(n, m, l, seed=0, ordering=None, new_embedding=False):\n",
    "    \"\"\"\n",
    "    As `sub_fht`, but computes in `l` blocks of size `n` by `m`, potentially\n",
    "    offering substantial speed improvements.\n",
    "\n",
    "    n: number of rows\n",
    "    m: number of columns per block\n",
    "    l: number of blocks\n",
    "\n",
    "    It is most efficient (though not required) when max(m,n+1) is a power of 2.\n",
    "\n",
    "    seed: determines choice of random matrix\n",
    "    ordering: optional (l, n) shaped array of row indices in [1, max(m, n)] to\n",
    "              implement subsampling; generated by seed if not specified, but\n",
    "              may be given to speed up subsequent runs on the same matrix.\n",
    "\n",
    "    Returns (Ax, Ay, ordering):\n",
    "        Ax(x): computes A.x (of length n), with x having length l*m\n",
    "        Ay(y): computes A'.y (of length l*m), with y having length n\n",
    "        ordering: the ordering in use, which may have been generated from seed\n",
    "    \"\"\"\n",
    "    assert n > 0, \"n must be positive\"\n",
    "    assert m > 0, \"m must be positive\"\n",
    "    assert l > 0, \"l must be positive\"\n",
    "\n",
    "    if ordering is not None:\n",
    "        assert ordering.shape == (l, n)\n",
    "    else:\n",
    "        if new_embedding:\n",
    "            w = 2**int(np.ceil(np.log2(max(m+1, n+1))))\n",
    "        else:\n",
    "            w = 2**int(np.ceil(np.log2(max(m, n+1))))\n",
    "        rng = np.random.RandomState(seed)\n",
    "        ordering = np.empty((l, n), dtype=np.uint32)\n",
    "        idxs = np.arange(1, w, dtype=np.uint32)\n",
    "        for ll in range(l):\n",
    "            rng.shuffle(idxs)\n",
    "            ordering[ll] = idxs[:n]\n",
    "\n",
    "    def Ax(x):\n",
    "        assert x.size == l*m\n",
    "        out = np.zeros(n)\n",
    "        for ll in range(l):\n",
    "            ax, ay, _ = sub_fht(n, m, ordering=ordering[ll],\n",
    "                                new_embedding=new_embedding)\n",
    "            out += ax(x[ll*m:(ll+1)*m])\n",
    "        return out\n",
    "\n",
    "    def Ay(y):\n",
    "        assert y.size == n\n",
    "        out = np.empty(l*m)\n",
    "        for ll in range(l):\n",
    "            ax, ay, _ = sub_fht(n, m, ordering=ordering[ll],\n",
    "                                new_embedding=new_embedding)\n",
    "            out[ll*m:(ll+1)*m] = ay(y)\n",
    "        return out\n",
    "\n",
    "    return Ax, Ay, ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Hadamard Transforms\n",
    "\n",
    "This code can all be found in `pyfht`, which uses a C extension to speed up the fht function. To make this notebook self contained, it's reproduced entirely in Python here, which will be quite slow!\n",
    "\n",
    "Skip to the next section if you're not interested in the specific transform implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfht import block_sub_fht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outer Tree encoder\n",
    "\n",
    "This function encodes the payloads corresponding to users into codewords from the specified tree code. \n",
    "\n",
    "Parity bits in section $i$ are generated based on the information sections $i$ is connected to\n",
    "\n",
    "Computations are done within the ring of integers modulo length of the section to enable FFT-based BP on the outer graph\n",
    "\n",
    "This function outputs the sparse representation of encoded messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Tree_encode(tx_message,K,messageBlocks,G,L,J):\n",
    "    encoded_tx_message = np.zeros((K,L),dtype=int)\n",
    "    \n",
    "    encoded_tx_message[:,0] = tx_message[:,0:J].dot(2**np.arange(J)[::-1])\n",
    "    for i in range(1,L):\n",
    "        if messageBlocks[i]:\n",
    "            # copy the message if i is an information section\n",
    "            encoded_tx_message[:,i] = tx_message[:,np.sum(messageBlocks[:i])*J:(np.sum(messageBlocks[:i])+1)*J].dot(2**np.arange(J)[::-1])\n",
    "        else:\n",
    "            # compute the parity if i is a parity section\n",
    "            indices = np.where(G[i])[0]\n",
    "            ParityInteger=np.zeros((K,1),dtype='int')\n",
    "            for j in indices:\n",
    "                ParityInteger1 = encoded_tx_message[:,j].reshape(-1,1)\n",
    "                ParityInteger = np.mod(ParityInteger+ParityInteger1,2**J)\n",
    "            encoded_tx_message[:,i] = ParityInteger.reshape(-1)\n",
    "    \n",
    "    return encoded_tx_message\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function converts message indices into $L$-sparse vectors of length $L 2^J$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_indices_to_sparse(encoded_tx_message_indices,L,J,K):\n",
    "    encoded_tx_message_sparse=np.zeros((L*2**J,1),dtype=int)\n",
    "    for i in range(L):\n",
    "        A = encoded_tx_message_indices[:,i]\n",
    "        B = A.reshape([-1,1])\n",
    "        np.add.at(encoded_tx_message_sparse, i*2**J+B, 1)        \n",
    "    return encoded_tx_message_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the index representation corresponding to a SPARC-like vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_sparse_to_indices(cs_decoded_tx_message_sparse,L,J,listSize):\n",
    "    cs_decoded_tx_message = np.zeros((listSize,L),dtype=int)\n",
    "    for i in range(L):\n",
    "        A = cs_decoded_tx_message_sparse[i*2**J:(i+1)*2**J]\n",
    "        idx = (A.reshape(2**J,)).argsort()[np.arange(2**J-listSize)]\n",
    "        B = np.setdiff1d(np.arange(2**J),idx)\n",
    "        cs_decoded_tx_message[:,i] = B \n",
    "\n",
    "    return cs_decoded_tx_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract information bits from retained paths in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_msg_indices(Paths,cs_decoded_tx_message, L,J):\n",
    "    msg_bits = np.empty(shape=(0,0))\n",
    "    L1 = Paths.shape[0]\n",
    "    for i in range(L1):\n",
    "        msg_bit=np.empty(shape=(0,0))\n",
    "        path = Paths[i].reshape(1,-1)\n",
    "        for j in range(path.shape[1]):\n",
    "            msg_bit = np.hstack((msg_bit,cs_decoded_tx_message[path[0,j],j].reshape(1,-1))) if msg_bit.size else cs_decoded_tx_message[path[0,j],j]\n",
    "            msg_bit=msg_bit.reshape(1,-1)\n",
    "        msg_bits = np.vstack((msg_bits,msg_bit)) if msg_bits.size else msg_bit           \n",
    "    return msg_bits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARC Codebook\n",
    "\n",
    "We use the `block_sub_fht` which computes the equivalent of $A.\\beta$ by using $L$ separate $M\\times M$ Hadamard matrices. However we want each entry to be divided by $\\sqrt{n}$ to get the right variance, and we need to do a reshape on the output to get column vectors, so we'll wrap those operations here.\n",
    "\n",
    "Returns two functions `Ab` and `Az` which compute $A\\cdot B$ and $z^T\\cdot A$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sparc_codebook(L, M, n,P):\n",
    "    Ax, Ay, _ = block_sub_fht(n, M, L, ordering=None)\n",
    "    def Ab(b):\n",
    "        return Ax(b).reshape(-1, 1)/ np.sqrt(n)\n",
    "    def Az(z):\n",
    "        return Ay(z).reshape(-1, 1)/ np.sqrt(n) \n",
    "    return Ab, Az"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BP on outer graph\n",
    "\n",
    "This function computes the priors on the unknown sparse vector, given effective obervations of the (graph) neighboring sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computePrior(s,G,messageBlocks,L,M,p0,K,τ,Phat,numBPiter):\n",
    "    \n",
    "    q = np.zeros(s.shape,dtype=float)\n",
    "    p1 = p0*np.ones(s.shape,dtype=float)\n",
    "    \n",
    "    for iter in range(numBPiter):\n",
    "        \n",
    "        # Translate the effective observation into PME. For the first iteration of BP, use the uninformative prior p0\n",
    "        temp_beta = (p1*np.exp(-(s-np.sqrt(Phat))**2/(2*τ**2)))/ (p1*np.exp(-(s-np.sqrt(Phat))**2/(2*τ**2)) + (1-p1)*np.exp(-s**2/(2*τ**2))).astype(float).reshape(-1, 1)\n",
    "\n",
    "    \n",
    "        # Reshape PME into an LxM matrix\n",
    "        Beta = temp_beta.reshape(L,-1)\n",
    "        #print(Beta.shape,np.sum(Beta,axis=1))\n",
    "        Beta = Beta/(np.sum(Beta,axis=1).reshape(L,-1))\n",
    "        # Rotate PME 180deg about y-axis\n",
    "        Betaflipped = np.hstack((Beta[:,0].reshape(-1,1),np.flip(Beta[:,1:],axis=1)))\n",
    "        # Compute and store all FFTs\n",
    "        BetaFFT = np.fft.fft(Beta)\n",
    "        BetaflippedFFT = np.fft.fft(Betaflipped)\n",
    "        for i in range(L):\n",
    "            if messageBlocks[i]:\n",
    "                # Parity sections connected to info section i\n",
    "                parityIndices = np.where(G[i])[0]\n",
    "                BetaIFFTprime = np.empty((0,0)).astype(float)\n",
    "                for j in parityIndices:\n",
    "                    # Other info blocks connected to this parity block\n",
    "                    messageIndices = np.setdiff1d(np.where(G[j])[0],i)\n",
    "                    BetaFFTprime = np.vstack((BetaFFT[j],BetaflippedFFT[messageIndices,:]))\n",
    "                    # Multiply the relevant FFTs\n",
    "                    BetaFFTprime = np.prod(BetaFFTprime,axis=0)\n",
    "                    # IFFT\n",
    "                    BetaIFFTprime1 = np.fft.ifft(BetaFFTprime).real\n",
    "                    BetaIFFTprime = np.vstack((BetaIFFTprime,BetaIFFTprime1)) if BetaIFFTprime.size else BetaIFFTprime1\n",
    "                BetaIFFTprime = np.prod(BetaIFFTprime,axis=0)\n",
    "            else:\n",
    "                BetaIFFTprime = np.empty((0,0)).astype(float)\n",
    "                # Information sections connected to this parity section (assuming no parity over parity sections)\n",
    "                Indices = np.where(G[i])[0]\n",
    "                # FFT\n",
    "                BetaFFTprime = BetaFFT[Indices,:]\n",
    "                # Multiply the relevant FFTs\n",
    "                BetaFFTprime = np.prod(BetaFFTprime,axis=0)\n",
    "                # IFFT\n",
    "                BetaIFFTprime = np.fft.ifft(BetaFFTprime).real\n",
    "            \n",
    "            # Normalize to ensure it sums to one\n",
    "            p1[i*M:(i+1)*M] = (BetaIFFTprime/np.sum(BetaIFFTprime)).reshape(-1,1)\n",
    "            p1[i*M:(i+1)*M]  = 1-(1-p1[i*M:(i+1)*M] )**K \n",
    "            # Normalize to ensure sum of priors within a section is K (optional)\n",
    "            #p1[i*M:(i+1)*M] = p1[i*M:(i+1)*M]*K/np.sum(p1[i*M:(i+1)*M])\n",
    "         \n",
    "    q = np.minimum(p1,1)          \n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMP\n",
    "This is the actual AMP algorithm. It's a mostly straightforward transcription from the relevant equations, but note we use `longdouble` types because the expentials are often too big to fit into a normal `double`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def amp(y, σ_n, P, L, M, T, Ab, Az,p0,K,G,messageBlocks,BPonOuterGraph,numBPiter):\n",
    "\n",
    "    n = y.size\n",
    "    β = np.zeros((L*M, 1))\n",
    "    z = y\n",
    "    Phat = n*P/L\n",
    "    # Store the values of τ corresponding to each iteration\n",
    "    τ_evolution = np.zeros((T,1))\n",
    "    \n",
    "    for t in range(T):\n",
    "        \n",
    "        # Compute τ online using the residual\n",
    "        τ = np.sqrt(np.sum(z**2)/n)\n",
    "        \n",
    "        # effective observation\n",
    "        s = (np.sqrt(Phat)*β + Az(z)).astype(np.longdouble)\n",
    "        \n",
    "        if BPonOuterGraph==0:\n",
    "            # Use the uninformative prior p0 for Giuseppe's scheme\n",
    "            q = p0\n",
    "        else:\n",
    "            # Compute the prior through BP on outer graph\n",
    "            q = computePrior(s,G,messageBlocks,L,M,p0,K,τ,Phat,numBPiter)\n",
    "            \n",
    "        # denoiser\n",
    "        β = (q*np.exp(-(s-np.sqrt(Phat))**2/(2*τ**2)))/ (q*np.exp(-(s-np.sqrt(Phat))**2/(2*τ**2)) + (1-q)*np.exp(-s**2/(2*τ**2))).astype(float).reshape(-1, 1)\n",
    "        \n",
    "        # residual\n",
    "        z = y - np.sqrt(Phat)*Ab(β) + (z/(n*τ**2)) * (Phat*np.sum(β) - Phat*np.sum(β**2))\n",
    "        #print(t,τ)\n",
    "        τ_evolution[t] = τ\n",
    "\n",
    "    return β,τ_evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outer Tree decoder\n",
    "\n",
    "This function implements the tree deocoder for a specific graph corresponding to the outer tree code\n",
    "\n",
    "It is currently hard-coded for a specfic architecture\n",
    "\n",
    "The architecture is based on a tri-adic design and can be found in the simulation results section of https://arxiv.org/pdf/2001.03705.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Tree_decoder(cs_decoded_tx_message,G,L,J,B,listSize):\n",
    "    \n",
    "    tree_decoded_tx_message = np.empty(shape=(0,0))\n",
    "    \n",
    "    Paths012 = merge_paths(cs_decoded_tx_message[:,0:3])\n",
    "    \n",
    "    Paths345 = merge_paths(cs_decoded_tx_message[:,3:6])\n",
    "    \n",
    "    Paths678 = merge_paths(cs_decoded_tx_message[:,6:9])\n",
    "    \n",
    "    Paths91011 = merge_paths(cs_decoded_tx_message[:,9:12])\n",
    "    \n",
    "    Paths01267812 = merge_pathslevel2(Paths012,Paths678,cs_decoded_tx_message[:,[0,6,12]])\n",
    "    \n",
    "    Paths3459101113 = merge_pathslevel2(Paths345,Paths91011,cs_decoded_tx_message[:,[3,9,13]])\n",
    "    \n",
    "    Paths01267812345910111314 = merge_all_paths0(Paths01267812,Paths3459101113,cs_decoded_tx_message[:,[1,4,10,14]])\n",
    "    \n",
    "    Paths = merge_all_paths_final(Paths01267812345910111314,cs_decoded_tx_message[:,[7,10,15]])\n",
    "    \n",
    "    \n",
    "   \n",
    "    return Paths\n",
    "\n",
    "def merge_paths(A):\n",
    "    listSize = A.shape[0]\n",
    "    B = np.array([np.mod(A[:,0] + a,2**16) for a in A[:,1]]).flatten()\n",
    "     \n",
    "    Paths=np.empty((0,0))\n",
    "    \n",
    "    for i in range(listSize):\n",
    "        I = np.where(B==A[i,2])[0].reshape(-1,1)\n",
    "        if I.size:\n",
    "            I1 = np.hstack([np.mod(I,listSize).reshape(-1,1),np.floor(I/listSize).reshape(-1,1)]).astype(int)\n",
    "            Paths = np.vstack((Paths,np.hstack([I1,np.repeat(i,I.shape[0]).reshape(-1,1)]))) if Paths.size else np.hstack([I1,np.repeat(i,I.shape[0]).reshape(-1,1)])\n",
    "    \n",
    "    return Paths\n",
    "\n",
    "def merge_pathslevel2(Paths012,Paths678,A):\n",
    "    listSize = A.shape[0]\n",
    "    Paths0 = Paths012[:,0]\n",
    "    Paths6 = Paths678[:,0]\n",
    "    B = np.array([np.mod(A[Paths0,0] + a,2**16) for a in A[Paths6,1]]).flatten()\n",
    "    \n",
    "    Paths=np.empty((0,0))\n",
    "    \n",
    "    for i in range(listSize):\n",
    "        I = np.where(B==A[i,2])[0].reshape(-1,1)\n",
    "        if I.size:\n",
    "            I1 = np.hstack([np.mod(I,Paths0.shape[0]).reshape(-1,1),np.floor(I/Paths0.shape[0]).reshape(-1,1)]).astype(int)\n",
    "            PPaths = np.hstack((Paths012[I1[:,0]].reshape(-1,3),Paths678[I1[:,1]].reshape(-1,3),np.repeat(i,I1.shape[0]).reshape(-1,1)))\n",
    "            Paths = np.vstack((Paths,PPaths)) if Paths.size else PPaths\n",
    "               \n",
    "    return Paths\n",
    "\n",
    "\n",
    "def merge_all_paths0(Paths01267812,Paths3459101113,A):\n",
    "    listSize = A.shape[0]\n",
    "    Paths1 = Paths01267812[:,1]\n",
    "    Paths4 = Paths3459101113[:,1]\n",
    "    Paths10 = Paths3459101113[:,4]\n",
    "    Aa = np.mod(A[Paths4,1]+A[Paths10,2],2**16)\n",
    "    B = np.array([np.mod(A[Paths1,0] + a,2**16) for a in Aa]).flatten()\n",
    "    \n",
    "    Paths=np.empty((0,0))\n",
    "    \n",
    "    for i in range(listSize):\n",
    "        I = np.where(B==A[i,3])[0].reshape(-1,1)\n",
    "        if I.size:\n",
    "            I1 = np.hstack([np.mod(I,Paths1.shape[0]).reshape(-1,1),np.floor(I/Paths1.shape[0]).reshape(-1,1)]).astype(int)\n",
    "            PPaths = np.hstack((Paths01267812[I1[:,0]].reshape(-1,7),Paths3459101113[I1[:,1]].reshape(-1,7),np.repeat(i,I1.shape[0]).reshape(-1,1)))\n",
    "            Paths = np.vstack((Paths,PPaths)) if Paths.size else PPaths\n",
    "    \n",
    "    return Paths\n",
    "\n",
    "def merge_all_paths_final(Paths01267812345910111314,A):\n",
    "    \n",
    "    listSize = A.shape[0]\n",
    "    Paths7 = Paths01267812345910111314[:,4]\n",
    "    Paths10 = Paths01267812345910111314[:,11]\n",
    "    B = np.mod(A[Paths7,0] + A[Paths10,1] ,2**16)\n",
    "    \n",
    "    Paths=np.empty((0,0))\n",
    "    \n",
    "    for i in range(listSize):\n",
    "        I = np.where(B==A[i,2])[0].reshape(-1,1)\n",
    "        if I.size:\n",
    "            PPaths = np.hstack((Paths01267812345910111314[I].reshape(-1,15),np.repeat(i,I.shape[0]).reshape(-1,1)))\n",
    "            Paths = np.vstack((Paths,PPaths)) if Paths.size else PPaths\n",
    "    return Paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If tree decoder outputs more than $K$ valid paths, retain $K-\\delta$ of them based on their LLRs\n",
    "\n",
    "$\\delta$ is currently set to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_topKminusdelta_paths(Paths, cs_decoded_tx_message, β, J,K,delta):\n",
    "    \n",
    "    L1 = Paths.shape[0]\n",
    "    LogL = np.zeros((L1,1))\n",
    "    for i in range(L1):\n",
    "        msg_bit=np.empty(shape=(0,0))\n",
    "        path = Paths[i].reshape(1,-1)\n",
    "        for j in range(path.shape[1]):\n",
    "            msg_bit = np.hstack((msg_bit,j*(2**J)+cs_decoded_tx_message[path[0,j],j].reshape(1,-1))) if msg_bit.size else j*(2**J)+cs_decoded_tx_message[path[0,j],j]\n",
    "            msg_bit=msg_bit.reshape(1,-1)\n",
    "        LogL[i] = np.sum(np.log(β[msg_bit])) \n",
    "    Indices =  LogL.reshape(1,-1).argsort()[0,-(K-delta):]\n",
    "    Paths = Paths[Indices,:].reshape(((K-delta),-1))\n",
    "    \n",
    "    return Paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=25 # Number of active users\n",
    "B=128 # Payload size of each active user\n",
    "L=16 # Number of sections/sub-blocks\n",
    "n=38400 # Total number of channel uses (real d.o.f)\n",
    "T=6 # Number of AMP iterations\n",
    "listSize = 4*K  # List size retained for each section after AMP converges\n",
    "J=16  # Length of each coded sub-block\n",
    "M=2**J # Length of each section\n",
    "messageBlocks = np.array([1,1,0,1,1,0,1,1,0,1,1,0,0,0,0,0]).astype(int) # Indicates the indices of information blocks\n",
    "# Adjacency matrix of the outer code/graph\n",
    "G = np.zeros((L,L)).astype(int)\n",
    "# G contains info on what parity blocks a message is attached to and what message blocks a parity is involved with\n",
    "# Currently, we do not allow parity over parities. BP code needs to be modified a little to accomodate parity over parities\n",
    "G[0,[2,12]]=1\n",
    "G[1,[2,14]]=1\n",
    "G[2,[0,1]]=1\n",
    "G[3,[5,13]]=1\n",
    "G[4,[5,14]]=1\n",
    "G[5,[3,4]]=1\n",
    "G[6,[8,12]]=1\n",
    "G[7,[8,15]]=1\n",
    "G[8,[6,7]]=1\n",
    "G[9,[11,13]]=1\n",
    "G[10,[11,14,15]]=1\n",
    "G[11,[9,10]]=1\n",
    "G[12,[0,6]]=1\n",
    "G[13,[3,9]]=1\n",
    "G[14,[1,4,10]]=1\n",
    "G[15,[7,10]]=1\n",
    "BPonOuterGraph = 1 # Indicates if BP is allowed on the outer code.Setting this to zero defaults back to Giuseppe's scheme that uses uninformative prior\n",
    "numBPiter = 1; # Number of BP iterations on outer code. 1 seems to be good enough & AMP theory including state evolution valid only for one BP iteration\n",
    "EbNodB = 2.4 # Energy per bit. With iterative extension, operating EbN0 falls to 2.05 dB for 25 users with 1 round SIC\n",
    "p0 = 1-(1-1/M)**K # Giuseppe's uninformative prior\n",
    "delta = 0\n",
    "maxSims=10 # number of simulations\n",
    "\n",
    "# EbN0 in linear scale\n",
    "EbNo = 10**(EbNodB/10)\n",
    "P = 2*B*EbNo/n\n",
    "σ_n = 1\n",
    "#Generate the power allocation and set of tau coefficients\n",
    "\n",
    "# We assume equal power allocation for all the sections. Code has to be modified a little to accomodate non-uniform power allocations\n",
    "Phat = n*P/L\n",
    "\n",
    "msgDetected=0\n",
    "\n",
    "for sims in range(maxSims):\n",
    "    \n",
    "    # Generate active users message sequences\n",
    "    tx_message = np.random.randint(2, size=(K,B))\n",
    "    \n",
    "    # Outer-encode the message sequences\n",
    "    encoded_tx_message_indices = Tree_encode(tx_message,K,messageBlocks,G,L,J)\n",
    "\n",
    "    # Convert indices to sparse representation\n",
    "    β_0 = convert_indices_to_sparse(encoded_tx_message_indices,L,J,K)\n",
    "    \n",
    "    # Generate the binned SPARC codebook\n",
    "    Ab, Az = sparc_codebook(L, M, n, P)\n",
    "    \n",
    "    # Generate our transmitted signal X\n",
    "    x = np.sqrt(Phat)*Ab(β_0)\n",
    "    \n",
    "    # Generate random channel noise and thus also received signal y\n",
    "    z = np.random.randn(n, 1) * σ_n\n",
    "    y = (x + z).reshape(-1, 1)\n",
    "\n",
    "    # Run AMP decoding\n",
    "    β, τ_evolution = amp(y, σ_n, P, L, M, T, Ab, Az,p0,K,G,messageBlocks,BPonOuterGraph,numBPiter)\n",
    "    print(f'Shape of Beta: {np.shape(β)}')\n",
    "\n",
    "    # Convert decoded sparse vector into vector of indices  \n",
    "    cs_decoded_tx_message = convert_sparse_to_indices(β,L,J,listSize)\n",
    "    print(f'Shape of cs_decoded_tx_message: {np.shape(cs_decoded_tx_message)}')\n",
    "    \n",
    "    # Tree decoder to decode individual messages from lists output by AMP\n",
    "    Paths = Tree_decoder(cs_decoded_tx_message,G,L,J,B,listSize)\n",
    "    print(f'Shape of Paths: {np.shape(Paths)}')\n",
    "    \n",
    "    # Re-align paths to the correct order\n",
    "    perm = np.argsort(np.array([0,1,2,6,7,8,12,3,4,5,9,10,11,13,14,15]))\n",
    "    Paths = Paths[:,perm]\n",
    "    print(f'Shape of Paths: {np.shape(Paths)}')\n",
    "    \n",
    "   \n",
    "    # If tree deocder outputs more than K valid paths, retain only K of them\n",
    "    if Paths.shape[0] > K:\n",
    "        Paths = pick_topKminusdelta_paths(Paths, cs_decoded_tx_message, β, J, K,0)\n",
    "\n",
    "    # Extract the message indices from valid paths in the tree    \n",
    "    Tree_decoded_indices = extract_msg_indices(Paths,cs_decoded_tx_message, L,J)\n",
    "    print(f'Shape of Tree_decoded_indices: {np.shape(Tree_decoded_indices)}' )\n",
    "    \n",
    "    # Calculation of per-user prob err\n",
    "    for i in range(K):\n",
    "        msgDetected = msgDetected + np.equal(encoded_tx_message_indices[i,:],Tree_decoded_indices).all(axis=1).any()\n",
    "\n",
    "    \n",
    "errorRate= (K*maxSims - msgDetected)/(K*maxSims)\n",
    "\n",
    "print(\"Per user probability of error = \", errorRate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
