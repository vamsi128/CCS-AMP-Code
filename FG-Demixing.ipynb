{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coded Demxing\n",
    "\n",
    "This notebook implements coded Demixing using the CCS-AMP encoder/decoder for multi-class unsourced random access using Hadamard design matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import FactorGraphGeneration as FGG\n",
    "\n",
    "OuterCode1 = FGG.Triadic8(16)\n",
    "OuterCode2 = FGG.Triadic8(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Hadamard Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfht import block_sub_fht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARC Codebook\n",
    "\n",
    "We use the `block_sub_fht` which computes the equivalent of $A.\\beta$ by using $L$ separate $M\\times M$ Hadamard matrices. However we want each entry to be divided by $\\sqrt{n}$ to get the right variance, and we need to do a reshape on the output to get column vectors, so we'll wrap those operations here.\n",
    "\n",
    "Returns two functions `Ab` and `Az` which compute $A\\cdot B$ and $z^T\\cdot A$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparc_codebook(L, M, n,P):\n",
    "    Ax, Ay, _ = block_sub_fht(n, M, L, seed=None, ordering=None) # seed must be explicit\n",
    "    def Ab(b):\n",
    "        return Ax(b).reshape(-1, 1) / np.sqrt(n)\n",
    "    def Az(z):\n",
    "        return Ay(z).reshape(-1, 1) / np.sqrt(n) \n",
    "    return Ab, Az"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Approximation\n",
    "\n",
    "This function outputs the closest approximation to the input vector given that its L1 norm is 1 and no entry is greater than 1/K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximateVector(x, K):    \n",
    "\n",
    "    # normalize initial value of x\n",
    "    xOrig = x / np.linalg.norm(x, ord=1)\n",
    "    \n",
    "    # create vector to hold best approximation of x\n",
    "    xHt = xOrig.copy()\n",
    "    u = np.zeros(len(xHt))\n",
    "    \n",
    "    # run approximation algorithm\n",
    "    while np.amax(xHt) > (1/K):\n",
    "        minIndices = np.argmin([(1/K)*np.ones(xHt.shape), xHt], axis=0)\n",
    "        xHt = np.min([(1/K)*np.ones(xHt.shape), xHt], axis=0)\n",
    "        \n",
    "        deficit = 1 - np.linalg.norm(xHt, ord=1)\n",
    "        \n",
    "        if deficit > 0:\n",
    "            mIxHtNorm = np.linalg.norm((xHt*minIndices), ord=1)\n",
    "            scaleFactor = (deficit + mIxHtNorm) / mIxHtNorm\n",
    "            xHt = scaleFactor*(minIndices*xHt) + (1/K)*(np.ones(xHt.shape) - minIndices)\n",
    "\n",
    "    # return admissible approximation of x\n",
    "    return xHt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior Mean Estimator (PME)\n",
    "\n",
    "This function implements the posterior mean estimator for situations where prior probabilities are uninformative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pme0(q, r, d, tau):\n",
    "    \"\"\"Posterior mean estimator (PME)\n",
    "    \n",
    "    Args:\n",
    "        q (float): Prior probability\n",
    "        r (float): Effective observation\n",
    "        d (float): Signal amplitude\n",
    "        tau (float): Standard deviation of noise\n",
    "    Returns:\n",
    "        sHat (float): Probability s is one\n",
    "    \n",
    "    \"\"\"\n",
    "    sHat = ( q*np.exp( -(r-d)**2 / (2*(tau**2)) ) \\\n",
    "            / ( q*np.exp( -(r-d)**2 / (2*(tau**2))) + (1-q)*np.exp( -r**2 / (2*(tau**2))) ) ).astype(float)\n",
    "    return sHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Denoiser\n",
    "\n",
    "This function performs believe propagation (BP) on the factor graph of the outer code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamicDenoiser(r,p0,OuterCode,K,tau,d,numBPiter):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        r (float): Effective observation\n",
    "        p0 (float): uninformative prior\n",
    "        d (float): Signal amplitude\n",
    "        tau (float): Standard deviation of noise\n",
    "    \"\"\"\n",
    "    M = OuterCode.sparseseclength\n",
    "    L = OuterCode.varcount\n",
    "\n",
    "    p1 = p0*np.ones(r.shape, dtype=float)\n",
    "    mu = np.zeros(r.shape, dtype=float)\n",
    "\n",
    "    # Compute local estimate (lambda) based on effective observation using PME.\n",
    "    localEstimates = pme0(p0, r, d, tau)\n",
    "    \n",
    "    # Reshape local estimate (lambda) into an LxM matrix\n",
    "    Beta = localEstimates.reshape(L,-1)\n",
    "    OuterCode.reset()\n",
    "    for varnodeid in OuterCode.varlist:\n",
    "        idx = varnodeid - 1\n",
    "        Beta[idx,:] = approximateVector(Beta[idx,:], K)\n",
    "        OuterCode.setobservation(varnodeid, Beta[idx,:])\n",
    "    \n",
    "    for iteration in range(numBPiter):\n",
    "        OuterCode.updatechecks()\n",
    "        OuterCode.updatevars()\n",
    "\n",
    "    for varnodeid in OuterCode.varlist:\n",
    "        idx = varnodeid - 1\n",
    "        # Beta[idx,:] = OuterCode.getestimate(varnodeid)\n",
    "        Beta[idx,:] = OuterCode.getextrinsicestimate(varnodeid)\n",
    "        mu[idx*M:(idx+1)*M] = approximateVector(Beta[idx,:], K).reshape(-1,1)\n",
    "\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMP\n",
    "This is the actual AMP algorithm. It's a mostly straightforward transcription from the relevant equations, but note we use `longdouble` types because the expentials are often too big to fit into a normal `double`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_effective_observation(z, s, P, L, Az):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        z: Residual update through AMP composite iteration\n",
    "        s: State update through AMP composite iteration\n",
    "        P: transmit power\n",
    "        L: number of sections in the graph\n",
    "        Az: function used to compute A^T\n",
    "    \"\"\"\n",
    "    n = z.size\n",
    "    d = np.sqrt(n*P/L)\n",
    "\n",
    "    # Compute effective observation\n",
    "    return (d*s + Az(z.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FIXME: Note that in its current form, this function is\n",
    "#### designed to work ONLY when L1=L2 and M1=M2.  \n",
    "\n",
    "def amp_estimate_k_distribution(s1, s2, L1, L2, M1, M2, Ka):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        s1: current estimate of x1\n",
    "        s2: current estimate of x2\n",
    "        L1: number of sections in graph 1\n",
    "        L2: number of sections in graph 2\n",
    "        M1: length of each section in graph 1\n",
    "        M2: length of each section in graph 2\n",
    "        Ka: total number of users\n",
    "    \"\"\"\n",
    "    r1 = 0.0\n",
    "    r2 = 0.0\n",
    "\n",
    "    # Average over all L sections\n",
    "    for i in range(L):\n",
    "        w1 = s1[i*m:(i+1)*m]\n",
    "        w2 = s2[i*m:(i+1)*m]\n",
    "\n",
    "        idxw1 = np.argpartition(w1, -Ka, axis=0)[-Ka:]\n",
    "        idxw2 = np.argpartition(w2, -Ka, axis=0)[-Ka:]\n",
    "\n",
    "        sw1 = np.sum(w1[idxw1])\n",
    "        sw2 = np.sum(w2[idxw2])\n",
    "        \n",
    "        r1 += (sw1/(sw1+sw2))/L\n",
    "        r2 += (sw2/(sw1+sw2))/L\n",
    "\n",
    "    # Estimate number of active users\n",
    "    kr1 = Ka*r1\n",
    "    kr2 = Ka*r2\n",
    "\n",
    "    # Round estimate to nearest integer\n",
    "    k1ht = round(kr1)\n",
    "    k2ht = round(kr2)\n",
    "    print('K1 estimate: ', k1ht)\n",
    "    print('K2 estimate: ', k2ht)\n",
    "\n",
    "    # Compute measure of confidence in answer\n",
    "    kr1d = kr1 % 1\n",
    "    kr2d = kr2 % 1\n",
    "    confidenceLevel = np.abs(kr1d-kr2d)\n",
    "    confident = (confidenceLevel >= 0.3)\n",
    "    print('Confidence level: ', cl)\n",
    "    print('Confident? ', confident)\n",
    "\n",
    "    # Return estimates of K1, K2 as well as confidence\n",
    "    return (k1ht, k2ht, confident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_state_update(r, z, P, L, Kht, numBPiter, OuterCode, confident):\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        r: Effective observation\n",
    "        z: Residual update through AMP composite iteration\n",
    "        P: transmit power\n",
    "        L: number of sections\n",
    "        Kht: estimated number of users\n",
    "        numBPiter: number of BP to perform on outer graph\n",
    "        OuterCode: outer graph\n",
    "        confident (bool): indicates whether there is confidence in Kht\n",
    "    \"\"\"\n",
    "    n = z.size\n",
    "    m = r.size\n",
    "    d = np.sqrt(n*P/L)\n",
    "\n",
    "    # Compute tau online using the residual\n",
    "    tau = np.sqrt(np.sum(z**2)/n)\n",
    "\n",
    "    # Uninformative prior\n",
    "    if not confident:\n",
    "        p0 = 1-(1-1/(2*m))**Kht \n",
    "    else:\n",
    "        p0 = 1-(1-1/m)**Kht\n",
    "\n",
    "    # Compute updated state\n",
    "    mu = dynamicDenoiser(r, p0, OuterCode, Kht, tau, d, numBPiter)\n",
    "    s = pme0(mu, r, d, tau)\n",
    "        \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_residual(y, z, s1, s2, d1, d2, Ab1, Ab2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        s1: State update through AMP composite iteration\n",
    "        s2: State update through AMP composite iteration\n",
    "        y: Original observation\n",
    "        tau (float): Standard deviation of noise\n",
    "    \"\"\"\n",
    "    n = y.size\n",
    "    \n",
    "    # Compute tau online using the residual\n",
    "    tau = np.sqrt(np.sum(z**2)/n)\n",
    "\n",
    "    # Compute residual\n",
    "    Onsager1 = (d1**2)*(np.sum(s1) - np.sum(s1**2))\n",
    "    Onsager2 = (d2**2)*(np.sum(s2) - np.sum(s2**2))   \n",
    "    z_plus = y - d1*Ab1(s1) - d2*Ab2(s2)+ (z/(n*tau**2))*(Onsager1 + Onsager2)\n",
    "    \n",
    "    return z_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ka=24 # total number of active users\n",
    "\n",
    "B1=128 # Payload size of every active user in group 1\n",
    "B2=128 # B2=96 # Payload size of every active user in group 2\n",
    "\n",
    "L1=16 # Number of sections/sub-blocks in group 1\n",
    "L2=16 # Number of sections/sub-blocks in group 2\n",
    "\n",
    "n=38400 # Total number of channel uses (real d.o.f)\n",
    "T=10 # Number of AMP iterations\n",
    "J1=16  # Length of each coded sub-block\n",
    "J2=16  # Length of each coded sub-block\n",
    "M1=2**J1 # Length of each section\n",
    "M2=2**J2 # Length of each section\n",
    "\n",
    "numBPiter = 1; # Number of BP iterations on outer code. 1 seems to be good enough & AMP theory including state evolution valid only for one BP iteration\n",
    "EbNodB = 1.8 # Energy per bit. With iterative extension, operating EbN0 falls to 2.05 dB for 25 users with 1 round SIC\n",
    "simCount = 2 # number of simulations\n",
    "\n",
    "# EbN0 in linear scale\n",
    "EbNo = 10**(EbNodB/10)\n",
    "P1 = 2*B1*EbNo/n\n",
    "P2 = 2*B2*EbNo/n\n",
    "σ_n = 1\n",
    "\n",
    "# We assume equal power allocation for all the sections. Code has to be modified a little to accomodate non-uniform power allocations\n",
    "Phat1 = n*P1/L1\n",
    "Phat2 = n*P2/L2\n",
    "d1 = np.sqrt(n*P1/L1)\n",
    "d2 = np.sqrt(n*P2/L2)\n",
    "\n",
    "msgDetected1=0\n",
    "msgDetected2=0\n",
    "K1Sum = 0\n",
    "K2Sum = 0\n",
    "\n",
    "for simIndex in range(simCount):\n",
    "    print('Simulation Number: ' + str(simIndex))\n",
    "    \n",
    "    # Ka users select their groups:\n",
    "    K1 = np.sum(np.random.randn(Ka) > 0)\n",
    "    K2 = Ka - K1\n",
    "    \n",
    "    # Ki Estimates\n",
    "    K1ht = Ka\n",
    "    K2ht = Ka\n",
    "    trustKiHt = False\n",
    "    \n",
    "    # Increment KiSums\n",
    "    K1Sum += K1\n",
    "    K2Sum += K2\n",
    "    \n",
    "    # Generate active users message sequences\n",
    "    messages1 = np.random.randint(2, size=(K1, B1))\n",
    "    messages2 = np.random.randint(2, size=(K2, B2))\n",
    "\n",
    "    # Outer-encode the message sequences\n",
    "    codewords1 = OuterCode1.encodemessages(messages1)\n",
    "    for codeword1 in codewords1:\n",
    "        OuterCode1.testvalid(codeword1)\n",
    "    codewords2 = OuterCode2.encodemessages(messages2)\n",
    "    for codeword2 in codewords2:\n",
    "        OuterCode2.testvalid(codeword2)\n",
    "\n",
    "    # Convert indices to sparse representation\n",
    "    # sTrue: True state\n",
    "    sTrue1 = np.sum(codewords1, axis=0)\n",
    "    sTrue2 = np.sum(codewords2, axis=0)\n",
    "\n",
    "    # Generate the binned SPARC codebook\n",
    "    Ab1, Az1 = sparc_codebook(L1, M1, n, P1)\n",
    "    Ab2, Az2 = sparc_codebook(L2, M2, n, P2)\n",
    "    \n",
    "    # Generate our transmitted signal X\n",
    "    x = d1*Ab1(sTrue1) + d2*Ab2(sTrue2)\n",
    "    \n",
    "    # Generate random channel noise and thus also received signal y\n",
    "    noise = np.random.randn(n, 1) * σ_n\n",
    "    y = (x + noise)\n",
    "\n",
    "    z = y.copy()\n",
    "    s1 = np.zeros((L1*M1, 1))\n",
    "    s2 = np.zeros((L2*M2, 1))\n",
    "\n",
    "    for t in range(T):\n",
    "        r1 = amp_effective_observation(z ,s1, P1, L1, Az1)\n",
    "        r2 = amp_effective_observation(z, s2, P2, L2, Az2)\n",
    "        \n",
    "        s1 = amp_state_update(r1, z, P1, L1, K1ht, numBPiter, OuterCode1, confident)\n",
    "        s2 = amp_state_update(r2, z, P2, L2, K2ht, numBPiter, OuterCode2, confident)\n",
    "        \n",
    "        if not trustKiHt:\n",
    "            k1ht, k2ht, trustKiHt = amp_estimate_k_distribution(s1, s2, L1, L2, M1, M2, Ka)\n",
    "            K1ht = k1ht if trustKiHt else K1ht\n",
    "            K2ht = k2ht if trustKiHt else K2ht\n",
    "\n",
    "        z = amp_residual(y, z, s1, s2, d1, d2, Ab1, Ab2)\n",
    "\n",
    "    print('Graph Decode')\n",
    "    \n",
    "    # Decoding wiht Graph\n",
    "    originallist1 = codewords1.copy()\n",
    "    originallist2 = codewords2.copy()\n",
    "    recoveredcodewords1 = OuterCode1.decoder(s1, 17)\n",
    "    recoveredcodewords2 = OuterCode2.decoder(s2, 17)\n",
    "\n",
    "    # Calculation of per-user prob err\n",
    "    simMsgDetected1 = 0\n",
    "    simMsgDetected2 = 0\n",
    "    matches1 = FGG.numbermatches(originallist1, recoveredcodewords1)\n",
    "    matches2 = FGG.numbermatches(originallist2, recoveredcodewords2)\n",
    "    \n",
    "    print('Group 1: ' + str(matches1) + ' out of ' + str(K1))\n",
    "    print('Group 2: ' + str(matches2) + ' out of ' + str(K2))\n",
    "    msgDetected1 = msgDetected1 + matches1\n",
    "    msgDetected2 = msgDetected2 + matches2\n",
    "    \n",
    "errorRate1= (K1Sum - msgDetected1) / K1Sum\n",
    "errorRate2= (K2Sum - msgDetected2) / K2Sum\n",
    "\n",
    "print(\"Per user probability of error (Group 1) = \", errorRate1)\n",
    "print(\"Per user probability of error (Group 2) = \", errorRate2)\n",
    "print(\"Per user probability of error average =  \", 0.5*(errorRate1+errorRate2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}