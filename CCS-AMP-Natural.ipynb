{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCS-AMP for Unsourced Multiple Access\n",
    "\n",
    "This notebook contains CCS-AMP encoder/decoder for unsourced multiple access using Hadamard design matrices.\n",
    "The proposed algorithm goes back and forth between inner AMP and outer tree decoding components.\n",
    "\n",
    "The code is based on the following articles:\n",
    "* [A coded compressed sensing scheme for uncoordinated multiple access](https://arxiv.org/abs/1809.04745)\n",
    "* [SPARCs for Unsourced Random Access](https://arxiv.org/abs/1901.06234)\n",
    "* [On Approximate Message Passing for Unsourced Access with Coded Compressed Sensing](https://arxiv.org/abs/2001.03705)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Hadamard Transforms\n",
    "\n",
    "The ```PyFHT_local``` code can all be found in `pyfht`, which uses a C extension to speed up the fht function.\n",
    "Only one import suffices, with the latter being much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyFHT_local\n",
    "from pyfht import block_sub_fht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outer Tree encoder\n",
    "\n",
    "This function encodes the payloads corresponding to users into codewords from the specified tree code. \n",
    "\n",
    "Parity bits in section $i$ are generated based on the information sections $i$ is connected to\n",
    "\n",
    "Computations are done within the ring of integers modulo length of the section to enable FFT-based BP on the outer graph\n",
    "\n",
    "This function outputs the sparse representation of encoded messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tree_encode(tx_message,K,messageBlocks,G,L,J):\n",
    "    encoded_tx_message = np.zeros((K,L),dtype=int)\n",
    "    \n",
    "    encoded_tx_message[:,0] = tx_message[:,0:J].dot(2**np.arange(J)[::-1])\n",
    "    for i in range(1,L):\n",
    "        if messageBlocks[i]:\n",
    "            # copy the message if i is an information section\n",
    "            encoded_tx_message[:,i] = tx_message[:,np.sum(messageBlocks[:i])*J:(np.sum(messageBlocks[:i])+1)*J].dot(2**np.arange(J)[::-1])\n",
    "        else:\n",
    "            # compute the parity if i is a parity section\n",
    "            indices = np.where(G[i])[0]\n",
    "            ParityInteger=np.zeros((K,1),dtype='int')\n",
    "            for j in indices:\n",
    "                ParityInteger1 = encoded_tx_message[:,j].reshape(-1,1)\n",
    "                ParityInteger = np.mod(ParityInteger+ParityInteger1,2**J)\n",
    "            encoded_tx_message[:,i] = ParityInteger.reshape(-1)\n",
    "    \n",
    "    return encoded_tx_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function converts message indices into $L$-sparse vectors of length $L 2^J$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_indices_to_sparse(encoded_tx_message_indices,L,J,K):\n",
    "    encoded_tx_message_sparse=np.zeros((L*2**J,1),dtype=int)\n",
    "    for i in range(L):\n",
    "        A = encoded_tx_message_indices[:,i]\n",
    "        B = A.reshape([-1,1])\n",
    "        np.add.at(encoded_tx_message_sparse, i*2**J+B, 1)\n",
    "\n",
    "    return encoded_tx_message_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the index representation corresponding to a SPARC-like vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_to_indices(cs_decoded_tx_message_sparse,L,J,listSize):\n",
    "    cs_decoded_tx_message = np.zeros((listSize,L),dtype=int)\n",
    "    for i in range(L):\n",
    "        A = cs_decoded_tx_message_sparse[i*2**J:(i+1)*2**J]\n",
    "        idx = (A.reshape(2**J,)).argsort()[np.arange(2**J-listSize)]\n",
    "        B = np.setdiff1d(np.arange(2**J),idx)\n",
    "        cs_decoded_tx_message[:,i] = B \n",
    "\n",
    "    return cs_decoded_tx_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract information bits from retained paths in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_msg_indices(Paths,cs_decoded_tx_message, L,J):\n",
    "    msg_bits = np.empty(shape=(0,0))\n",
    "    L1 = Paths.shape[0]\n",
    "    for i in range(L1):\n",
    "        msg_bit=np.empty(shape=(0,0))\n",
    "        path = Paths[i].reshape(1,-1)\n",
    "        for j in range(path.shape[1]):\n",
    "            msg_bit = np.hstack((msg_bit,cs_decoded_tx_message[path[0,j],j].reshape(1,-1))) if msg_bit.size else cs_decoded_tx_message[path[0,j],j]\n",
    "            msg_bit=msg_bit.reshape(1,-1)\n",
    "        msg_bits = np.vstack((msg_bits,msg_bit)) if msg_bits.size else msg_bit\n",
    "\n",
    "    return msg_bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARC Codebook\n",
    "\n",
    "We use the `block_sub_fht` which computes the equivalent of $A.\\beta$ by using $L$ separate $M\\times M$ Hadamard matrices. However we want each entry to be divided by $\\sqrt{n}$ to get the right variance, and we need to do a reshape on the output to get column vectors, so we'll wrap those operations here.\n",
    "\n",
    "Returns two functions `Ab` and `Az` which compute $A\\cdot B$ and $z^T\\cdot A$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparc_codebook(L, M, n,P):\n",
    "    Ax, Ay, _ = block_sub_fht(n, M, L, ordering=None)\n",
    "    def Ab(b):\n",
    "        return Ax(b).reshape(-1, 1)/ np.sqrt(n)\n",
    "    def Az(z):\n",
    "        return Ay(z).reshape(-1, 1)/ np.sqrt(n) \n",
    "    return Ab, Az"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Approximation\n",
    "\n",
    "This function outputs the closest approximation to the input vector given that its L1 norm is 1 and no entry is greater than 1/K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximateVector(x, K):    \n",
    "\n",
    "    # normalize initial value of x\n",
    "    xOrig = x / np.linalg.norm(x, ord=1)\n",
    "    \n",
    "    # create vector to hold best approximation of x\n",
    "    xHt = xOrig.copy()\n",
    "    u = np.zeros(len(xHt))\n",
    "    \n",
    "    # run approximation algorithm\n",
    "    while np.amax(xHt) > (1/K):\n",
    "        minIndices = np.argmin([(1/K)*np.ones(xHt.shape), xHt], axis=0)\n",
    "        xHt = np.min([(1/K)*np.ones(xHt.shape), xHt], axis=0)\n",
    "        \n",
    "        deficit = 1 - np.linalg.norm(xHt, ord=1)\n",
    "        \n",
    "        if deficit > 0:\n",
    "            mIxHtNorm = np.linalg.norm((xHt*minIndices), ord=1)\n",
    "            scaleFactor = (deficit + mIxHtNorm) / mIxHtNorm\n",
    "            xHt = scaleFactor*(minIndices*xHt) + (1/K)*(np.ones(xHt.shape) - minIndices)\n",
    "\n",
    "    # return admissible approximation of x\n",
    "    return xHt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Mean Estimator (PME)\n",
    "\n",
    "This function implements the posterior mean estimator for situations where prior probabilities are uninformative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pme0(q, r, d, τ):\n",
    "    \"\"\"Posterior mean estimator (PME)\n",
    "    \n",
    "    Args:\n",
    "        q (float): Prior probability\n",
    "        r (float): Effective observation\n",
    "        d (float): Signal amplitude\n",
    "        τ (float): Standard deviation of noise\n",
    "    Returns:\n",
    "        sHat (float): Probability s is one\n",
    "    \n",
    "    \"\"\"\n",
    "    sHat = ((q*np.exp(-(r-d)**2/(2*τ**2))) \\\n",
    "            / (q*np.exp(-(r-d)**2/(2*τ**2)) + (1-q)*np.exp(-r**2/(2*τ**2)))).astype(float)\n",
    "    return sHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Denoiser\n",
    "\n",
    "This function performs believe propagation (BP) on the factor graph of the outer code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamicDenoiser(r,G,messageBlocks,L,M,K,τ,d,numBPiter):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        r (float): Effective observation\n",
    "        d (float): Signal amplitude\n",
    "        τ (float): Standard deviation of noise\n",
    "    \"\"\"\n",
    "    p0 = 1-(1-1/M)**K\n",
    "    p1 = p0*np.ones(r.shape,dtype=float)\n",
    "    mu = np.zeros(r.shape,dtype=float)\n",
    "\n",
    "    # Compute local estimate (lambda) based on effective observation using PME.\n",
    "    localEstimates = pme0(p0, r, d, τ)\n",
    "    \n",
    "    # Reshape local estimate (lambda) into an LxM matrix\n",
    "    Beta = localEstimates.reshape(L,-1)\n",
    "    for i in range(L):\n",
    "        Beta[i,:] = approximateVector(Beta[i,:], K)\n",
    "\n",
    "    # There is an issue BELOW for numBPiter greater than one!\n",
    "    for iter in range(numBPiter):    \n",
    "        #print(Beta.shape,np.sum(Beta,axis=1))\n",
    "        Beta = Beta/(np.sum(Beta,axis=1).reshape(L,-1))\n",
    "\n",
    "        # Rotate PME 180deg about y-axis\n",
    "        Betaflipped = np.hstack((Beta[:,0].reshape(-1,1),np.flip(Beta[:,1:],axis=1)))\n",
    "        # Compute and store all FFTs\n",
    "        BetaFFT = np.fft.fft(Beta)\n",
    "        BetaflippedFFT = np.fft.fft(Betaflipped)\n",
    "        for i in range(L):\n",
    "            if messageBlocks[i]:\n",
    "                # Parity sections connected to info section i\n",
    "                parityIndices = np.where(G[i])[0]\n",
    "                BetaIFFTprime = np.empty((0,0)).astype(float)\n",
    "                for j in parityIndices:\n",
    "                    # Other info blocks connected to this parity block\n",
    "                    messageIndices = np.setdiff1d(np.where(G[j])[0],i)\n",
    "                    BetaFFTprime = np.vstack((BetaFFT[j],BetaflippedFFT[messageIndices,:]))\n",
    "                    # Multiply the relevant FFTs\n",
    "                    BetaFFTprime = np.prod(BetaFFTprime,axis=0)\n",
    "                    # IFFT\n",
    "                    BetaIFFTprime1 = np.fft.ifft(BetaFFTprime).real\n",
    "                    BetaIFFTprime = np.vstack((BetaIFFTprime,BetaIFFTprime1)) if BetaIFFTprime.size else BetaIFFTprime1\n",
    "                BetaIFFTprime = np.prod(BetaIFFTprime,axis=0)\n",
    "            else:\n",
    "                BetaIFFTprime = np.empty((0,0)).astype(float)\n",
    "                # Information sections connected to this parity section (assuming no parity over parity sections)\n",
    "                Indices = np.where(G[i])[0]\n",
    "                # FFT\n",
    "                BetaFFTprime = BetaFFT[Indices,:]\n",
    "                # Multiply the relevant FFTs\n",
    "                BetaFFTprime = np.prod(BetaFFTprime,axis=0)\n",
    "                # IFFT\n",
    "                BetaIFFTprime = np.fft.ifft(BetaFFTprime).real            \n",
    "            mu[i*M:(i+1)*M] = approximateVector(BetaIFFTprime, K).reshape(-1,1)\n",
    "\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMP\n",
    "This is the actual AMP algorithm. It's a mostly straightforward transcription from the relevant equations, but note we use `longdouble` types because the expentials are often too big to fit into a normal `double`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp(y, P, L, M, T, Ab, Az,K,G,messageBlocks,denoiserType,numBPiter):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        s: State update through AMP composite iteration\n",
    "        z: Residual update through AMP composite iteration\n",
    "        τ (float): Standard deviation of noise\n",
    "        mu: Product of messages from adjoining factors\n",
    "    \"\"\"\n",
    "    n = y.size\n",
    "    s = np.zeros((L*M, 1))\n",
    "    z = y.copy()\n",
    "    Phat = n*P/L\n",
    "    d = np.sqrt(Phat)\n",
    "    # Store the values of τ corresponding to each iteration\n",
    "    τ_evolution = np.zeros((T,1))\n",
    "    \n",
    "    for t in range(T):\n",
    "        \n",
    "        # Compute τ online using the residual\n",
    "        τ = np.sqrt(np.sum(z**2)/n)\n",
    "        τ_evolution[t] = τ\n",
    "        \n",
    "        # Compute effective observation\n",
    "        r = (d*s + Az(z)).astype(np.longdouble)\n",
    "\n",
    "        # Compute updated state\n",
    "        # HERE: It remains unclear what to constrain and renormalize\n",
    "        if denoiserType==0:\n",
    "            # Use the uninformative prior p0 for Giuseppe's scheme\n",
    "            p0 = 1-(1-1/M)**K\n",
    "            s = pme0(p0, r, d, τ)\n",
    "            z = y - d*Ab(s) + (z/(n*τ**2))*Phat*(np.sum(s) - np.sum(s**2))\n",
    "        elif denoiserType==1:\n",
    "            mu = dynamicDenoiser(r,G,messageBlocks,L,M,K,τ,d,numBPiter)\n",
    "            s = pme0(mu, r, d, τ)\n",
    "            z = y - d*Ab(s) + (z/(n*τ**2))*Phat*(np.sum(s) - np.sum(s**2))\n",
    "        else:\n",
    "            # Compute beliefs using BP on outer graph\n",
    "            p0 = 1-(1-1/M)**K\n",
    "            LocalEstimates = pme0(p0, r, d, τ).reshape((L,-1))\n",
    "            mu = dynamicDenoiser(r,G,messageBlocks,L,M,K,τ,d,numBPiter).reshape((L,-1))\n",
    "            NaturalEstimates = s.reshape((L,-1))\n",
    "            LambdaEstimate = np.zeros(s.shape).reshape((L,-1))\n",
    "            UpsilonVector = np.zeros(s.shape).reshape((L,-1))\n",
    "            IotaVector = np.zeros(s.shape).reshape((L,-1))\n",
    "            OnesVector = np.ones(s.shape).reshape((L,-1))\n",
    "            OnsagerVector = np.ones(s.shape).reshape((L,-1))\n",
    "            \n",
    "            Onsager = 0\n",
    "            for ell in range(L):\n",
    "                LambdaEstimate[ell,:] = LocalEstimates[ell,:]\n",
    "#                 LambdaEstimate[ell,:] = approximateVector(LocalEstimates[ell,:], K)\n",
    "                NaturalEstimates[ell,:] = approximateVector(LambdaEstimate[ell,:] * mu[ell,:], K)\n",
    "#                 UpsilonVector[ell,:] = [(1 - math.isclose(estimate, 1/K)) for estimate in LambdaEstimate[ell,:]]\n",
    "                IotaVector[ell,:] = [(1 - math.isclose(estimate, 1/K)) for estimate in NaturalEstimates[ell,:]]\n",
    "                OnsagerVector[ell,:] = (OnesVector[ell,:] - LocalEstimates[ell,:]) \\\n",
    "                    * (OnesVector[ell,:] - IotaVector[ell,:] * LambdaEstimate[ell,:] * mu[ell,:]/np.linalg.norm(IotaVector[ell,:] * LambdaEstimate[ell,:] * mu[ell,:], ord=1)) \\\n",
    "                    * IotaVector[ell,:] * LambdaEstimate[ell,:] * mu[ell,:]/np.linalg.norm(IotaVector[ell,:] * LambdaEstimate[ell,:] * mu[ell,:], ord=1) \\\n",
    "                    * (K - np.linalg.norm(OnesVector[ell,:] - IotaVector[ell,:], ord=1))\n",
    "#                     * (OnesVector[ell,:] - UpsilonVector[ell,:] * LocalEstimates[ell,:]/np.linalg.norm(UpsilonVector[ell,:] * LocalEstimates[ell,:], ord=1)) \\\n",
    "#                     * UpsilonVector[ell,:] \\\n",
    "                Onsager = Onsager + np.linalg.norm(OnsagerVector, ord=1)\n",
    "#                 math.isclose(a, b, abs_tol=0.00001)\n",
    "            s = K*NaturalEstimates.reshape(-1, 1)\n",
    "#             Onsager\n",
    "            z = y - d*Ab(s) + (z/(n*τ**2))*Phat*Onsager\n",
    "#             print('Upsilon Vector: ' + str(M*L - np.linalg.norm(UpsilonVector.reshape(-1, 1), ord=1)), end = ' and ')\n",
    "#             print('Iota Vector: ' + str(M*L - np.linalg.norm(IotaVector.reshape(-1, 1), ord=1)))\n",
    "        # Computation of residual\n",
    "        \n",
    "        \n",
    "    return s,τ_evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outer Tree decoder\n",
    "\n",
    "This function implements the tree deocoder for a specific graph corresponding to the outer tree code\n",
    "\n",
    "It is currently hard-coded for a specfic architecture\n",
    "\n",
    "The architecture is based on a tri-adic design and can be found in the simulation results section of https://arxiv.org/pdf/2001.03705.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tree_decoder(cs_decoded_tx_message,G,L,J,B,listSize):\n",
    "    \n",
    "    tree_decoded_tx_message = np.empty(shape=(0,0))\n",
    "    Paths012 = merge_paths(cs_decoded_tx_message[:,0:3])   \n",
    "    Paths345 = merge_paths(cs_decoded_tx_message[:,3:6])\n",
    "    Paths678 = merge_paths(cs_decoded_tx_message[:,6:9])\n",
    "    Paths91011 = merge_paths(cs_decoded_tx_message[:,9:12])\n",
    "    Paths01267812 = merge_pathslevel2(Paths012,Paths678,cs_decoded_tx_message[:,[0,6,12]])\n",
    "    Paths3459101113 = merge_pathslevel2(Paths345,Paths91011,cs_decoded_tx_message[:,[3,9,13]])\n",
    "    Paths01267812345910111314 = merge_all_paths0(Paths01267812,Paths3459101113,cs_decoded_tx_message[:,[1,4,10,14]])\n",
    "    Paths = merge_all_paths_final(Paths01267812345910111314,cs_decoded_tx_message[:,[7,10,15]])\n",
    "    \n",
    "    return Paths\n",
    "\n",
    "def merge_paths(A):\n",
    "    listSize = A.shape[0]\n",
    "    B = np.array([np.mod(A[:,0] + a,2**16) for a in A[:,1]]).flatten()\n",
    "     \n",
    "    Paths=np.empty((0,0))\n",
    "    \n",
    "    for i in range(listSize):\n",
    "        I = np.where(B==A[i,2])[0].reshape(-1,1)\n",
    "        if I.size:\n",
    "            I1 = np.hstack([np.mod(I,listSize).reshape(-1,1),np.floor(I/listSize).reshape(-1,1)]).astype(int)\n",
    "            Paths = np.vstack((Paths,np.hstack([I1,np.repeat(i,I.shape[0]).reshape(-1,1)]))) if Paths.size else np.hstack([I1,np.repeat(i,I.shape[0]).reshape(-1,1)])\n",
    "    \n",
    "    return Paths\n",
    "\n",
    "def merge_pathslevel2(Paths012,Paths678,A):\n",
    "    listSize = A.shape[0]\n",
    "    Paths0 = Paths012[:,0]\n",
    "    Paths6 = Paths678[:,0]\n",
    "    B = np.array([np.mod(A[Paths0,0] + a,2**16) for a in A[Paths6,1]]).flatten()\n",
    "    \n",
    "    Paths=np.empty((0,0))\n",
    "    \n",
    "    for i in range(listSize):\n",
    "        I = np.where(B==A[i,2])[0].reshape(-1,1)\n",
    "        if I.size:\n",
    "            I1 = np.hstack([np.mod(I,Paths0.shape[0]).reshape(-1,1),np.floor(I/Paths0.shape[0]).reshape(-1,1)]).astype(int)\n",
    "            PPaths = np.hstack((Paths012[I1[:,0]].reshape(-1,3),Paths678[I1[:,1]].reshape(-1,3),np.repeat(i,I1.shape[0]).reshape(-1,1)))\n",
    "            Paths = np.vstack((Paths,PPaths)) if Paths.size else PPaths\n",
    "               \n",
    "    return Paths\n",
    "\n",
    "\n",
    "def merge_all_paths0(Paths01267812,Paths3459101113,A):\n",
    "    listSize = A.shape[0]\n",
    "    Paths1 = Paths01267812[:,1]\n",
    "    Paths4 = Paths3459101113[:,1]\n",
    "    Paths10 = Paths3459101113[:,4]\n",
    "    Aa = np.mod(A[Paths4,1]+A[Paths10,2],2**16)\n",
    "    B = np.array([np.mod(A[Paths1,0] + a,2**16) for a in Aa]).flatten()\n",
    "    \n",
    "    Paths=np.empty((0,0))\n",
    "    \n",
    "    for i in range(listSize):\n",
    "        I = np.where(B==A[i,3])[0].reshape(-1,1)\n",
    "        if I.size:\n",
    "            I1 = np.hstack([np.mod(I,Paths1.shape[0]).reshape(-1,1),np.floor(I/Paths1.shape[0]).reshape(-1,1)]).astype(int)\n",
    "            PPaths = np.hstack((Paths01267812[I1[:,0]].reshape(-1,7),Paths3459101113[I1[:,1]].reshape(-1,7),np.repeat(i,I1.shape[0]).reshape(-1,1)))\n",
    "            Paths = np.vstack((Paths,PPaths)) if Paths.size else PPaths\n",
    "    \n",
    "    return Paths\n",
    "\n",
    "def merge_all_paths_final(Paths01267812345910111314,A):\n",
    "    \n",
    "    listSize = A.shape[0]\n",
    "    Paths7 = Paths01267812345910111314[:,4]\n",
    "    Paths10 = Paths01267812345910111314[:,11]\n",
    "    B = np.mod(A[Paths7,0] + A[Paths10,1] ,2**16)\n",
    "    \n",
    "    Paths=np.empty((0,0))\n",
    "    \n",
    "    for i in range(listSize):\n",
    "        I = np.where(B==A[i,2])[0].reshape(-1,1)\n",
    "        if I.size:\n",
    "            PPaths = np.hstack((Paths01267812345910111314[I].reshape(-1,15),np.repeat(i,I.shape[0]).reshape(-1,1)))\n",
    "            Paths = np.vstack((Paths,PPaths)) if Paths.size else PPaths\n",
    "    return Paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If tree decoder outputs more than $K$ valid paths, retain $K-\\delta$ of them based on their LLRs\n",
    "\n",
    "$\\delta$ is currently set to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_topKminusdelta_paths(Paths, cs_decoded_tx_message, β, J,K,delta):\n",
    "    \n",
    "    L1 = Paths.shape[0]\n",
    "    LogL = np.zeros((L1,1))\n",
    "    for i in range(L1):\n",
    "        msg_bit=np.empty(shape=(0,0))\n",
    "        path = Paths[i].reshape(1,-1)\n",
    "        for j in range(path.shape[1]):\n",
    "            msg_bit = np.hstack((msg_bit,j*(2**J)+cs_decoded_tx_message[path[0,j],j].reshape(1,-1))) if msg_bit.size else j*(2**J)+cs_decoded_tx_message[path[0,j],j]\n",
    "            msg_bit=msg_bit.reshape(1,-1)\n",
    "        LogL[i] = np.sum(np.log(β[msg_bit])) \n",
    "    Indices =  LogL.reshape(1,-1).argsort()[0,-(K-delta):]\n",
    "    Paths = Paths[Indices,:].reshape(((K-delta),-1))\n",
    "    \n",
    "    return Paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Number: 0\n",
      "Dynamic PME: 24 out of 25\n",
      "Natural BP: 24 out of 25\n",
      "Simulation Number: 1\n",
      "Dynamic PME: 24 out of 25\n",
      "Natural BP: 23 out of 25\n",
      "Simulation Number: 2\n",
      "Dynamic PME: 22 out of 25\n",
      "Natural BP: 23 out of 25\n",
      "Simulation Number: 3\n",
      "Dynamic PME: 25 out of 25\n",
      "Natural BP: 24 out of 25\n",
      "Simulation Number: 4\n",
      "Dynamic PME: 24 out of 25\n",
      "Natural BP: 24 out of 25\n",
      "Per user probability of error (Dynamic PME) =  0.048\n",
      "Per user probability of error (Natural BP) =  0.056\n"
     ]
    }
   ],
   "source": [
    "K=25 # Number of active users\n",
    "B=128 # Payload size of each active user\n",
    "L=16 # Number of sections/sub-blocks\n",
    "n=38400 # Total number of channel uses (real d.o.f)\n",
    "T=8 # Number of AMP iterations\n",
    "listSize = 4*K  # List size retained for each section after AMP converges\n",
    "J=16  # Length of each coded sub-block\n",
    "M=2**J # Length of each section\n",
    "messageBlocks = np.array([1,1,0,1,1,0,1,1,0,1,1,0,0,0,0,0]).astype(int) # Indicates the indices of information blocks\n",
    "# Adjacency matrix of the outer code/graph\n",
    "G = np.zeros((L,L)).astype(int)\n",
    "# G contains info on what parity blocks a message is attached to and what message blocks a parity is involved with\n",
    "# Currently, we do not allow parity over parities. BP code needs to be modified a little to accomodate parity over parities\n",
    "G[0,[2,12]]=1\n",
    "G[1,[2,14]]=1\n",
    "G[2,[0,1]]=1\n",
    "G[3,[5,13]]=1\n",
    "G[4,[5,14]]=1\n",
    "G[5,[3,4]]=1\n",
    "G[6,[8,12]]=1\n",
    "G[7,[8,15]]=1\n",
    "G[8,[6,7]]=1\n",
    "G[9,[11,13]]=1\n",
    "G[10,[11,14,15]]=1\n",
    "G[11,[9,10]]=1\n",
    "G[12,[0,6]]=1\n",
    "G[13,[3,9]]=1\n",
    "G[14,[1,4,10]]=1\n",
    "G[15,[7,10]]=1\n",
    "denoiserType = 2 # Select denoiser: 0 - Original PME; 1 - Dynamic PME; 2+ - Natrual BP.\n",
    "numBPiter = 1; # Number of BP iterations on outer code. 1 seems to be good enough & AMP theory including state evolution valid only for one BP iteration\n",
    "EbNodB = 2.4 # Energy per bit. With iterative extension, operating EbN0 falls to 2.05 dB for 25 users with 1 round SIC\n",
    "delta = 0\n",
    "simCount = 5 # number of simulations\n",
    "\n",
    "# EbN0 in linear scale\n",
    "EbNo = 10**(EbNodB/10)\n",
    "P = 2*B*EbNo/n\n",
    "σ_n = 1\n",
    "#Generate the power allocation and set of tau coefficients\n",
    "\n",
    "# We assume equal power allocation for all the sections. Code has to be modified a little to accomodate non-uniform power allocations\n",
    "Phat = n*P/L\n",
    "\n",
    "# msgDetected0=0\n",
    "msgDetected1=0\n",
    "msgDetected2=0\n",
    "\n",
    "for simIndex in range(simCount):\n",
    "    print('Simulation Number: ' + str(simIndex))\n",
    "    \n",
    "    # Generate active users message sequences\n",
    "    tx_message = np.random.randint(2, size=(K,B))\n",
    "    \n",
    "    # Outer-encode the message sequences\n",
    "    encoded_tx_message_indices = Tree_encode(tx_message,K,messageBlocks,G,L,J)\n",
    "\n",
    "    # Convert indices to sparse representation\n",
    "    # sTrue: True state\n",
    "    sTrue = convert_indices_to_sparse(encoded_tx_message_indices, L, J, K)\n",
    "    \n",
    "    # Generate the binned SPARC codebook\n",
    "    Ab, Az = sparc_codebook(L, M, n, P)\n",
    "    \n",
    "    # Generate our transmitted signal X\n",
    "    x = np.sqrt(Phat)*Ab(sTrue)\n",
    "    \n",
    "    # Generate random channel noise and thus also received signal y\n",
    "    z = np.random.randn(n, 1) * σ_n\n",
    "    y = (x + z).reshape(-1, 1)\n",
    "\n",
    "    # Run AMP decoding\n",
    "#     β0, τ_evolution0 = amp(y, P, L, M, T, Ab, Az, K, G, messageBlocks, 0, numBPiter)\n",
    "    β1, τ_evolution1 = amp(y, P, L, M, T, Ab, Az, K, G, messageBlocks, 1, numBPiter)\n",
    "    β2, τ_evolution2 = amp(y, P, L, M, T, Ab, Az, K, G, messageBlocks, 2, numBPiter)\n",
    "\n",
    "    # Convert decoded sparse vector into vector of indices  \n",
    "#     cs_decoded_tx_message0 = convert_sparse_to_indices(β0, L, J, listSize)\n",
    "    cs_decoded_tx_message1 = convert_sparse_to_indices(β1, L, J, listSize)\n",
    "    cs_decoded_tx_message2 = convert_sparse_to_indices(β2, L, J, listSize)\n",
    "\n",
    "    # Tree decoder to decode individual messages from lists output by AMP\n",
    "#     Paths0 = Tree_decoder(cs_decoded_tx_message0,G,L,J,B,listSize)\n",
    "    Paths1 = Tree_decoder(cs_decoded_tx_message1,G,L,J,B,listSize)\n",
    "    Paths2 = Tree_decoder(cs_decoded_tx_message2,G,L,J,B,listSize)\n",
    "    \n",
    "    # Re-align paths to the correct order\n",
    "    perm = np.argsort(np.array([0,1,2,6,7,8,12,3,4,5,9,10,11,13,14,15]))\n",
    "#     Paths0 = Paths0[:,perm]\n",
    "    Paths1 = Paths1[:,perm]\n",
    "    Paths2 = Paths2[:,perm]\n",
    "    \n",
    "    # If tree deocder outputs more than K valid paths, retain only K of them\n",
    "#     if Paths0.shape[0] > K:\n",
    "#         Paths0 = pick_topKminusdelta_paths(Paths0, cs_decoded_tx_message0, β0, J, K,0)\n",
    "    if Paths1.shape[0] > K:\n",
    "        Paths1 = pick_topKminusdelta_paths(Paths1, cs_decoded_tx_message1, β1, J, K,0)\n",
    "    if Paths2.shape[0] > K:\n",
    "        Paths2 = pick_topKminusdelta_paths(Paths2, cs_decoded_tx_message2, β2, J, K,0)\n",
    "\n",
    "    # Extract the message indices from valid paths in the tree    \n",
    "#     Tree_decoded_indices0 = extract_msg_indices(Paths0,cs_decoded_tx_message0, L,J)\n",
    "    Tree_decoded_indices1 = extract_msg_indices(Paths1,cs_decoded_tx_message1, L,J)\n",
    "    Tree_decoded_indices2 = extract_msg_indices(Paths2,cs_decoded_tx_message2, L,J)\n",
    "\n",
    "    # Calculation of per-user prob err\n",
    "#     simMsgDetected0 = 0\n",
    "    simMsgDetected1 = 0\n",
    "    simMsgDetected2 = 0\n",
    "    for i in range(K):\n",
    "#         simMsgDetected0 = simMsgDetected0 + (np.equal(encoded_tx_message_indices[i,:],Tree_decoded_indices0).all(axis=1).any()).astype(int)\n",
    "        simMsgDetected1 = simMsgDetected1 + (np.equal(encoded_tx_message_indices[i,:],Tree_decoded_indices1).all(axis=1).any()).astype(int)\n",
    "        simMsgDetected2 = simMsgDetected2 + (np.equal(encoded_tx_message_indices[i,:],Tree_decoded_indices2).all(axis=1).any()).astype(int)\n",
    "#     msgDetected0 = msgDetected0 + simMsgDetected0\n",
    "    msgDetected1 = msgDetected1 + simMsgDetected1\n",
    "    msgDetected2 = msgDetected2 + simMsgDetected2\n",
    "#     print('Original PME: ' + str(simMsgDetected0) + ' out of ' + str(K))\n",
    "    print('Dynamic PME: ' + str(simMsgDetected1) + ' out of ' + str(K))\n",
    "    print('Natural BP: ' + str(simMsgDetected2) + ' out of ' + str(K))\n",
    "# errorRate0= (K*simCount - msgDetected0)/(K*simCount)\n",
    "errorRate1= (K*simCount - msgDetected1)/(K*simCount)\n",
    "errorRate2= (K*simCount - msgDetected2)/(K*simCount)\n",
    "\n",
    "# print(\"Per user probability of error (Original PME) = \", errorRate0)\n",
    "print(\"Per user probability of error (Dynamic PME) = \", errorRate1)\n",
    "print(\"Per user probability of error (Natural BP) = \", errorRate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
